<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Datasets on DILab</title>
    <link>https://dilab-scu.github.io/nlp/dataset/</link>
    <description>Recent content in Datasets on DILab</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>&amp;copy; Your Name, 2016 </copyright><atom:link href="https://dilab-scu.github.io/nlp/dataset/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ancient Chinese Couplet Dataset</title>
      <link>https://dilab-scu.github.io/nlp/dataset/ancient-chinese-couplet-dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dilab-scu.github.io/nlp/dataset/ancient-chinese-couplet-dataset/</guid>
      <description>Introduction The dataset contains 774,491 ancient chinese couplets.
Download Link Download
Paper AnchiBERT: A Pre-Trained Model for Ancient ChineseLanguage Understanding and Generation, arXiv 2020. [Paper]</description>
    </item>
    
    <item>
      <title>Ancient Poems Dataset</title>
      <link>https://dilab-scu.github.io/nlp/dataset/ancient-poems-dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dilab-scu.github.io/nlp/dataset/ancient-poems-dataset/</guid>
      <description>Introduction The datasets contains 232,670 quatrains. Each quatrain consists of 4 lines of sentences, and the length of each line is fixed to 5 or 7 characters.
Download Link Download
Paper Generating Chinese Poetry from Images via Concrete and Abstract Information, IJCNN 2020 [Paper]
A Multi-Modal Chinese Poetry Generation Model, IJCNN 2018 [Paper]
Generating Style-specific Chinese Tang Poetry with a Simple Actor-Critic Model, TETCI 2018 [Paper]</description>
    </item>
    
    <item>
      <title>Ancient-Modern Chinese Dataset</title>
      <link>https://dilab-scu.github.io/nlp/dataset/ancient-modern-chinese-dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dilab-scu.github.io/nlp/dataset/ancient-modern-chinese-dataset/</guid>
      <description>Introduction We create a new large-scale Ancient-Modern Chinese parallel corpus which contains 1.24M bilingual pairs. To our best knowledge, this is the first large high-quality Ancient-Modern Chinese dataset which includes 984,611 pairs in training set, 48,980 pairs in validation set, and 50,000 pairs in test set.
Download Link Download
Paper Ancient-Modern Chinese Translation with a New Large Training Dataset, TALLIP 2019 [Paper]
An Automatic Evaluation Metric for Ancient-Modern Chinese Translation, Neural Computing and Applications.</description>
    </item>
    
    <item>
      <title>Chinese Dialogue Dataset</title>
      <link>https://dilab-scu.github.io/nlp/dataset/chinese-dialogue-dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dilab-scu.github.io/nlp/dataset/chinese-dialogue-dataset/</guid>
      <description>Introduction Prepocessed dataset containing 240k QA examples.
Download Link Download</description>
    </item>
    
    <item>
      <title>Chinese Sentence Making Corpus</title>
      <link>https://dilab-scu.github.io/nlp/dataset/chinese-sentence-making-corpus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dilab-scu.github.io/nlp/dataset/chinese-sentence-making-corpus/</guid>
      <description>Introduction This datasts contains 2,445,164 sentences consisting of daily used words and idioms, each word and idioms have more than one example sentence.
Download Link Download
Paper BFGAN: Backward and Forward Generative Adversarial Networks for Lexically Constrained Sentence Generation, TASLP 2019 [Paper]</description>
    </item>
    
    <item>
      <title>Dataset about users giving comments to items on Chinese websites</title>
      <link>https://dilab-scu.github.io/nlp/dataset/dataset-about-users-giving-comments-to-items-on-chinese-websites/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dilab-scu.github.io/nlp/dataset/dataset-about-users-giving-comments-to-items-on-chinese-websites/</guid>
      <description>Introduction The dataset contains 586,538 sentences about user comments, which cover both positive and negetive comments.
Download Link Download
Paper Âµ-Forcing: Training Variational Recurrent Autoencoders for Text Generation, TALLIP 2019 [Paper][Code]</description>
    </item>
    
    <item>
      <title>Medical Questions Generating Dataset</title>
      <link>https://dilab-scu.github.io/nlp/dataset/medical-questions-generating-dataset/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://dilab-scu.github.io/nlp/dataset/medical-questions-generating-dataset/</guid>
      <description>Introduction Preprocessed dataset containing 1.06 million medical QA examples.
Download Link Download</description>
    </item>
    
  </channel>
</rss>
